processId: 1190
prarent processId: 1
{
    "train_set": "../SemEval2DocRED/train_annotated_0.1.json",
    "dev_set": "../SemEval2DocRED/dev.json",
    "test_set": "../SemEval2DocRED/test.json",
    "train_set_save": "../SemEval2DocRED/prepro_data/train_BERT.pkl",
    "dev_set_save": "../SemEval2DocRED/prepro_data/dev_BERT.pkl",
    "test_set_save": "../SemEval2DocRED/prepro_data/test_BERT.pkl",
    "checkpoint_dir": "checkpoint",
    "fig_result_dir": "fig_result",
    "model_name": "SemEVAL_0.1",
    "pretrain_model": "",
    "vocabulary_size": 200000,
    "relation_nums": 11,
    "entity_type_num": 7,
    "max_entity_num": 80,
    "word_pad": 0,
    "entity_type_pad": 0,
    "entity_id_pad": 0,
    "word_emb_size": 10,
    "pre_train_word": false,
    "data_word_vec": null,
    "finetune_word": false,
    "use_entity_type": true,
    "entity_type_size": 20,
    "use_entity_id": true,
    "entity_id_size": 20,
    "nlayers": 1,
    "lstm_hidden_size": 32,
    "lstm_dropout": 0.1,
    "lr": 0.001,
    "batch_size": 5,
    "test_batch_size": 16,
    "epoch": 300,
    "test_epoch": 1,
    "weight_decay": 0.0001,
    "negativa_alpha": 4.0,
    "log_step": 20,
    "save_model_freq": 15,
    "mention_drop": false,
    "gcn_layers": 2,
    "gcn_dim": 808,
    "dropout": 0.6,
    "activation": "relu",
    "bert_hid_size": 768,
    "bert_path": "../PLM/bert-base-uncased",
    "bert_fix": false,
    "coslr": true,
    "clip": -1,
    "k_fold": "none",
    "use_model": "bert",
    "input_theta": -1,
    "transfer_learning": false
}
Reading data from ../SemEval2DocRED/train_annotated_0.1.json.
load preprocessed data from ../SemEval2DocRED/prepro_data/train_BERT.pkl.
Reading data from ../SemEval2DocRED/dev.json.
load preprocessed data from ../SemEval2DocRED/prepro_data/dev_BERT.pkl.
total parameters: 216617540
2021-06-30 15:03:00.942461 training from scratch with lr 0.001
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
False
2021-06-30 15:03:00.967324 begin..
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 15:03:19.204688 | epoch  1 | step   20 |  ms/b 911.86 | train loss 464.376 | NA acc: 0.85 | not NA acc: 0.11  | tot acc: 0.48 
2021-06-30 15:03:38.202072 | epoch  1 | step   40 |  ms/b 949.86 | train loss 177.770 | NA acc: 0.93 | not NA acc: 0.12  | tot acc: 0.53 
2021-06-30 15:03:54.482050 | epoch  1 | step   60 |  ms/b 813.98 | train loss 156.036 | NA acc: 0.95 | not NA acc: 0.15  | tot acc: 0.55 
2021-06-30 15:04:14.882746 | epoch  1 | step   80 |  ms/b 1020.03 | train loss 152.103 | NA acc: 0.96 | not NA acc: 0.18  | tot acc: 0.57 
2021-06-30 15:04:33.262478 | epoch  1 | step  100 |  ms/b 918.94 | train loss 126.332 | NA acc: 0.97 | not NA acc: 0.23  | tot acc: 0.60 
2021-06-30 15:04:49.822967 | epoch  1 | step  120 |  ms/b 828.00 | train loss 117.935 | NA acc: 0.97 | not NA acc: 0.26  | tot acc: 0.61 
2021-06-30 15:05:06.722991 | epoch  1 | step  140 |  ms/b 844.98 | train loss 119.226 | NA acc: 0.98 | not NA acc: 0.28  | tot acc: 0.63 
2021-06-30 15:05:23.463982 | epoch  1 | step  160 |  ms/b 837.03 | train loss 112.221 | NA acc: 0.98 | not NA acc: 0.31  | tot acc: 0.64 
2021-06-30 15:05:23.464363 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 15:05:31.652590 ALL  : Theta 0.4511 | F1 0.5399 | AUC 0.5932
2021-06-30 15:05:31.661341 Ignore ma_f1 0.5380 | inhput_theta 0.4511 test_result P 0.6210 test_result R 0.4720 test_result F1 0.5363 | AUC 0.5904
2021-06-30 15:05:31.663983 | epoch   1 | time:  8.20s
2021-06-30 15:05:31.664114 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 15:05:52.228923 | epoch  2 | step  180 |  ms/b 849.30 | train loss 89.537 | NA acc: 1.00 | not NA acc: 0.57  | tot acc: 0.79 
2021-06-30 15:06:08.490377 | epoch  2 | step  200 |  ms/b 813.06 | train loss 87.328 | NA acc: 1.00 | not NA acc: 0.60  | tot acc: 0.80 
2021-06-30 15:06:26.464726 | epoch  2 | step  220 |  ms/b 898.71 | train loss 79.822 | NA acc: 1.00 | not NA acc: 0.63  | tot acc: 0.82 
2021-06-30 15:06:43.960540 | epoch  2 | step  240 |  ms/b 874.78 | train loss 73.038 | NA acc: 1.00 | not NA acc: 0.65  | tot acc: 0.83 
2021-06-30 15:07:04.701304 | epoch  2 | step  260 |  ms/b 1037.02 | train loss 92.176 | NA acc: 1.00 | not NA acc: 0.64  | tot acc: 0.82 
2021-06-30 15:07:23.304160 | epoch  2 | step  280 |  ms/b 930.13 | train loss 73.630 | NA acc: 1.00 | not NA acc: 0.66  | tot acc: 0.83 
2021-06-30 15:07:40.841435 | epoch  2 | step  300 |  ms/b 876.85 | train loss 71.564 | NA acc: 1.00 | not NA acc: 0.66  | tot acc: 0.83 
2021-06-30 15:07:58.501282 | epoch  2 | step  320 |  ms/b 882.96 | train loss 75.232 | NA acc: 1.00 | not NA acc: 0.66  | tot acc: 0.83 
2021-06-30 15:07:58.501540 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 15:08:05.864846 ALL  : Theta 0.4448 | F1 0.7126 | AUC 0.7910
2021-06-30 15:08:05.873004 Ignore ma_f1 0.7108 | inhput_theta 0.4448 test_result P 0.7071 test_result R 0.7120 test_result F1 0.7095 | AUC 0.7890
2021-06-30 15:08:05.875112 | epoch   2 | time:  7.37s
2021-06-30 15:08:05.875144 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
