processId: 13959
prarent processId: 1
{
    "train_set": "../SemEval2DocRED/train_annotated_0.01.json",
    "dev_set": "../SemEval2DocRED/dev.json",
    "test_set": "../SemEval2DocRED/test.json",
    "train_set_save": "../SemEval2DocRED/prepro_data/train_BERT.pkl",
    "dev_set_save": "../SemEval2DocRED/prepro_data/dev_BERT.pkl",
    "test_set_save": "../SemEval2DocRED/prepro_data/test_BERT.pkl",
    "checkpoint_dir": "checkpoint",
    "fig_result_dir": "fig_result",
    "model_name": "SemEVAL_0.01",
    "pretrain_model": "",
    "vocabulary_size": 200000,
    "relation_nums": 11,
    "entity_type_num": 7,
    "max_entity_num": 80,
    "word_pad": 0,
    "entity_type_pad": 0,
    "entity_id_pad": 0,
    "word_emb_size": 10,
    "pre_train_word": false,
    "data_word_vec": null,
    "finetune_word": false,
    "use_entity_type": true,
    "entity_type_size": 20,
    "use_entity_id": true,
    "entity_id_size": 20,
    "nlayers": 1,
    "lstm_hidden_size": 32,
    "lstm_dropout": 0.1,
    "lr": 0.001,
    "batch_size": 5,
    "test_batch_size": 16,
    "epoch": 300,
    "test_epoch": 10,
    "weight_decay": 0.0001,
    "negativa_alpha": 4.0,
    "log_step": 20,
    "save_model_freq": 15,
    "mention_drop": false,
    "gcn_layers": 2,
    "gcn_dim": 808,
    "dropout": 0.6,
    "activation": "relu",
    "bert_hid_size": 768,
    "bert_path": "../PLM/bert-base-uncased",
    "bert_fix": false,
    "coslr": true,
    "clip": -1,
    "k_fold": "none",
    "use_model": "bert",
    "input_theta": -1,
    "transfer_learning": false
}
Reading data from ../SemEval2DocRED/train_annotated_0.01.json.
../PLM/bert-base-uncased
loading..
finish reading ../SemEval2DocRED/train_annotated_0.01.json and save preprocessed data to ../SemEval2DocRED/prepro_data/train_BERT.pkl.
Reading data from ../SemEval2DocRED/dev.json.
../PLM/bert-base-uncased
loading..
finish reading ../SemEval2DocRED/dev.json and save preprocessed data to ../SemEval2DocRED/prepro_data/dev_BERT.pkl.
total parameters: 216617540
2021-06-30 16:07:29.912472 training from scratch with lr 0.001
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
False
2021-06-30 16:07:36.010976 begin..
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:07:39.643732 | epoch  2 | step   20 |  ms/b 22.91 | train loss 483.674 | NA acc: 1.00 | not NA acc: 0.15  | tot acc: 0.57 
2021-06-30 16:07:41.924737 | epoch  3 | step   40 |  ms/b 45.87 | train loss 145.078 | NA acc: 1.00 | not NA acc: 0.45  | tot acc: 0.72 
2021-06-30 16:07:44.212450 | epoch  4 | step   60 |  ms/b 68.93 | train loss 79.138 | NA acc: 1.00 | not NA acc: 0.77  | tot acc: 0.88 
2021-06-30 16:07:46.547129 | epoch  5 | step   80 |  ms/b 93.62 | train loss 52.474 | NA acc: 1.00 | not NA acc: 0.90  | tot acc: 0.95 
2021-06-30 16:07:48.801643 | epoch  7 | step  100 |  ms/b 22.47 | train loss 30.821 | NA acc: 1.00 | not NA acc: 0.90  | tot acc: 0.95 
2021-06-30 16:07:51.131963 | epoch  8 | step  120 |  ms/b 46.39 | train loss 20.967 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.97 
2021-06-30 16:07:53.429093 | epoch  9 | step  140 |  ms/b 68.99 | train loss 18.588 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:07:55.735440 | epoch 10 | step  160 |  ms/b 92.25 | train loss 9.656 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:07:55.735770 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:07:57.801285 ALL  : Theta 0.0734 | F1 0.5254 | AUC 0.5319
2021-06-30 16:07:57.809457 Ignore ma_f1 0.5254 | inhput_theta 0.0734 test_result P 0.5852 test_result R 0.4740 test_result F1 0.5238 | AUC 0.5319
2021-06-30 16:07:57.811248 | epoch  10 | time:  2.08s
2021-06-30 16:07:57.811375 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:08:04.249254 | epoch 12 | step  180 |  ms/b 23.32 | train loss 10.975 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:06.667526 | epoch 13 | step  200 |  ms/b 48.91 | train loss 13.298 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:09.046566 | epoch 14 | step  220 |  ms/b 70.60 | train loss 3.676 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:11.365049 | epoch 15 | step  240 |  ms/b 92.52 | train loss 3.478 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:18.397894 | epoch 17 | step  260 |  ms/b 22.98 | train loss 1.915 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:20.725928 | epoch 18 | step  280 |  ms/b 46.93 | train loss 9.692 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:23.070215 | epoch 19 | step  300 |  ms/b 70.57 | train loss 14.093 | NA acc: 1.00 | not NA acc: 0.98  | tot acc: 0.99 
2021-06-30 16:08:25.397867 | epoch 20 | step  320 |  ms/b 93.05 | train loss 25.958 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:08:25.398116 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:08:27.525275 ALL  : Theta 0.2420 | F1 0.5112 | AUC 0.5016
2021-06-30 16:08:27.533578 Ignore ma_f1 0.5112 | inhput_theta 0.2420 test_result P 0.5772 test_result R 0.4560 test_result F1 0.5095 | AUC 0.5016
2021-06-30 16:08:27.535432 | epoch  20 | time:  2.14s
2021-06-30 16:08:27.535486 -----------------------------------------------------------------------------------------
2021-06-30 16:08:29.844164 | epoch 22 | step  340 |  ms/b 22.96 | train loss 7.057 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:32.237076 | epoch 23 | step  360 |  ms/b 48.02 | train loss 8.389 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:34.619337 | epoch 24 | step  380 |  ms/b 69.94 | train loss 6.284 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:36.934450 | epoch 25 | step  400 |  ms/b 92.69 | train loss 11.582 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:39.254041 | epoch 27 | step  420 |  ms/b 23.46 | train loss 12.260 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.97 
2021-06-30 16:08:41.572763 | epoch 28 | step  440 |  ms/b 47.32 | train loss 6.419 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:43.910221 | epoch 29 | step  460 |  ms/b 70.60 | train loss 19.199 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:46.217782 | epoch 30 | step  480 |  ms/b 91.90 | train loss 7.517 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:46.218092 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:08:48.418500 ALL  : Theta 0.0958 | F1 0.5236 | AUC 0.5035
2021-06-30 16:08:48.426552 Ignore ma_f1 0.5236 | inhput_theta 0.0958 test_result P 0.5370 test_result R 0.5080 test_result F1 0.5221 | AUC 0.5035
2021-06-30 16:08:48.428192 | epoch  30 | time:  2.21s
2021-06-30 16:08:48.428234 -----------------------------------------------------------------------------------------
2021-06-30 16:08:54.534695 | epoch 32 | step  500 |  ms/b 22.98 | train loss 5.708 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:56.843368 | epoch 33 | step  520 |  ms/b 45.83 | train loss 11.920 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:08:59.186412 | epoch 34 | step  540 |  ms/b 70.95 | train loss 9.933 | NA acc: 1.00 | not NA acc: 0.98  | tot acc: 0.99 
2021-06-30 16:09:01.540903 | epoch 35 | step  560 |  ms/b 94.36 | train loss 8.241 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:03.926573 | epoch 37 | step  580 |  ms/b 23.43 | train loss 6.919 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:06.256717 | epoch 38 | step  600 |  ms/b 46.61 | train loss 3.037 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:08.623332 | epoch 39 | step  620 |  ms/b 71.73 | train loss 1.412 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:10.990332 | epoch 40 | step  640 |  ms/b 92.52 | train loss 1.413 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:10.990581 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:09:13.094745 ALL  : Theta 0.0471 | F1 0.5635 | AUC 0.5618
2021-06-30 16:09:13.103026 Ignore ma_f1 0.5635 | inhput_theta 0.0471 test_result P 0.6032 test_result R 0.5260 test_result F1 0.5620 | AUC 0.5618
2021-06-30 16:09:13.105112 | epoch  40 | time:  2.11s
2021-06-30 16:09:13.105168 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:09:20.253011 | epoch 42 | step  660 |  ms/b 22.95 | train loss 1.343 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:22.549556 | epoch 43 | step  680 |  ms/b 45.92 | train loss 5.105 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:24.870593 | epoch 44 | step  700 |  ms/b 69.23 | train loss 4.983 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:27.173444 | epoch 45 | step  720 |  ms/b 92.16 | train loss 1.497 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:33.069697 | epoch 47 | step  740 |  ms/b 24.15 | train loss 0.350 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:35.375660 | epoch 48 | step  760 |  ms/b 45.72 | train loss 0.272 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:37.731111 | epoch 49 | step  780 |  ms/b 71.66 | train loss 0.067 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:40.071736 | epoch 50 | step  800 |  ms/b 93.51 | train loss 0.132 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:40.071995 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:09:42.273666 ALL  : Theta 0.0618 | F1 0.5655 | AUC 0.5568
2021-06-30 16:09:42.282241 Ignore ma_f1 0.5655 | inhput_theta 0.0618 test_result P 0.6713 test_result R 0.4860 test_result F1 0.5638 | AUC 0.5568
2021-06-30 16:09:42.284422 | epoch  50 | time:  2.21s
2021-06-30 16:09:42.284480 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:09:48.889634 | epoch 52 | step  820 |  ms/b 22.89 | train loss 0.535 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:51.256593 | epoch 53 | step  840 |  ms/b 47.20 | train loss 0.705 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:53.568263 | epoch 54 | step  860 |  ms/b 68.63 | train loss 0.037 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:55.861076 | epoch 55 | step  880 |  ms/b 91.66 | train loss 0.073 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:09:58.260493 | epoch 57 | step  900 |  ms/b 24.58 | train loss 0.497 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:00.651378 | epoch 58 | step  920 |  ms/b 47.19 | train loss 0.134 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:03.082204 | epoch 59 | step  940 |  ms/b 72.66 | train loss 0.539 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:05.394381 | epoch 60 | step  960 |  ms/b 92.64 | train loss 0.044 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:05.394665 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:10:07.533006 ALL  : Theta 0.0785 | F1 0.5747 | AUC 0.5728
2021-06-30 16:10:07.541128 Ignore ma_f1 0.5747 | inhput_theta 0.0785 test_result P 0.6823 test_result R 0.4940 test_result F1 0.5731 | AUC 0.5728
2021-06-30 16:10:07.542832 | epoch  60 | time:  2.15s
2021-06-30 16:10:07.542877 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:10:17.529112 | epoch 62 | step  980 |  ms/b 23.82 | train loss 0.305 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:19.876981 | epoch 63 | step 1000 |  ms/b 47.18 | train loss 0.079 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:22.218843 | epoch 64 | step 1020 |  ms/b 70.22 | train loss 0.088 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:24.505046 | epoch 65 | step 1040 |  ms/b 91.35 | train loss 0.025 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:26.825591 | epoch 67 | step 1060 |  ms/b 23.50 | train loss 0.037 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:29.162538 | epoch 68 | step 1080 |  ms/b 46.52 | train loss 0.092 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:31.457260 | epoch 69 | step 1100 |  ms/b 68.76 | train loss 0.034 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:33.862003 | epoch 70 | step 1120 |  ms/b 97.31 | train loss 0.419 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:33.862377 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:10:36.005097 ALL  : Theta 0.0546 | F1 0.5767 | AUC 0.5836
2021-06-30 16:10:36.013531 Ignore ma_f1 0.5767 | inhput_theta 0.0546 test_result P 0.6729 test_result R 0.5020 test_result F1 0.5750 | AUC 0.5836
2021-06-30 16:10:36.015814 | epoch  70 | time:  2.15s
2021-06-30 16:10:36.015984 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:10:43.048623 | epoch 72 | step 1140 |  ms/b 23.55 | train loss 0.068 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:45.391758 | epoch 73 | step 1160 |  ms/b 46.20 | train loss 0.150 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:47.813421 | epoch 74 | step 1180 |  ms/b 70.10 | train loss 0.044 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:50.055839 | epoch 75 | step 1200 |  ms/b 89.68 | train loss 0.115 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:57.043507 | epoch 77 | step 1220 |  ms/b 22.19 | train loss 0.044 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:10:59.278207 | epoch 78 | step 1240 |  ms/b 45.00 | train loss 0.214 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:01.542669 | epoch 79 | step 1260 |  ms/b 68.02 | train loss 0.043 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:03.853388 | epoch 80 | step 1280 |  ms/b 93.29 | train loss 0.034 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:03.853668 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:11:06.081053 ALL  : Theta 0.0543 | F1 0.5767 | AUC 0.5838
2021-06-30 16:11:06.101366 Ignore ma_f1 0.5767 | inhput_theta 0.0543 test_result P 0.6729 test_result R 0.5020 test_result F1 0.5750 | AUC 0.5838
2021-06-30 16:11:06.103411 | epoch  80 | time:  2.25s
2021-06-30 16:11:06.103458 -----------------------------------------------------------------------------------------
2021-06-30 16:11:08.519242 | epoch 82 | step 1300 |  ms/b 24.59 | train loss 0.120 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:10.931580 | epoch 83 | step 1320 |  ms/b 47.08 | train loss 0.071 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:13.259282 | epoch 84 | step 1340 |  ms/b 69.99 | train loss 0.201 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:15.549509 | epoch 85 | step 1360 |  ms/b 91.36 | train loss 0.043 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:18.041969 | epoch 87 | step 1380 |  ms/b 24.37 | train loss 0.080 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:20.412753 | epoch 88 | step 1400 |  ms/b 47.72 | train loss 0.481 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:22.741410 | epoch 89 | step 1420 |  ms/b 69.91 | train loss 0.026 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:25.039544 | epoch 90 | step 1440 |  ms/b 91.54 | train loss 0.114 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:25.039818 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:11:27.385268 ALL  : Theta 0.0614 | F1 0.5776 | AUC 0.5828
2021-06-30 16:11:27.393486 Ignore ma_f1 0.5776 | inhput_theta 0.0614 test_result P 0.6649 test_result R 0.5080 test_result F1 0.5760 | AUC 0.5828
2021-06-30 16:11:27.395394 | epoch  90 | time:  2.36s
2021-06-30 16:11:27.395521 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:11:37.204880 | epoch 92 | step 1460 |  ms/b 23.26 | train loss 0.036 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:39.566821 | epoch 93 | step 1480 |  ms/b 47.18 | train loss 0.118 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:41.934524 | epoch 94 | step 1500 |  ms/b 71.43 | train loss 0.080 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:44.263712 | epoch 95 | step 1520 |  ms/b 93.34 | train loss 0.102 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:46.530433 | epoch 97 | step 1540 |  ms/b 22.60 | train loss 0.156 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:48.813530 | epoch 98 | step 1560 |  ms/b 45.67 | train loss 0.907 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:51.089876 | epoch 99 | step 1580 |  ms/b 68.15 | train loss 0.144 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:53.384939 | epoch 100 | step 1600 |  ms/b 91.35 | train loss 0.531 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:53.385182 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:11:55.247405 ALL  : Theta 0.0686 | F1 0.5731 | AUC 0.5760
2021-06-30 16:11:55.255767 Ignore ma_f1 0.5731 | inhput_theta 0.0686 test_result P 0.6814 test_result R 0.4920 test_result F1 0.5714 | AUC 0.5760
2021-06-30 16:11:55.257463 | epoch 100 | time:  1.87s
2021-06-30 16:11:55.257505 -----------------------------------------------------------------------------------------
2021-06-30 16:11:57.515257 | epoch 102 | step 1620 |  ms/b 22.70 | train loss 0.616 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:11:59.713559 | epoch 103 | step 1640 |  ms/b 43.85 | train loss 0.098 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:01.941986 | epoch 104 | step 1660 |  ms/b 67.38 | train loss 0.054 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:04.363431 | epoch 105 | step 1680 |  ms/b 94.00 | train loss 1.097 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:09.635463 | epoch 107 | step 1700 |  ms/b 22.47 | train loss 0.126 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:11.969227 | epoch 108 | step 1720 |  ms/b 49.09 | train loss 0.501 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:14.318926 | epoch 109 | step 1740 |  ms/b 70.11 | train loss 0.345 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:16.770838 | epoch 110 | step 1760 |  ms/b 99.79 | train loss 0.031 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:16.771155 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:12:18.692385 ALL  : Theta 0.0466 | F1 0.5764 | AUC 0.5748
2021-06-30 16:12:18.700921 Ignore ma_f1 0.5764 | inhput_theta 0.0466 test_result P 0.6910 test_result R 0.4920 test_result F1 0.5748 | AUC 0.5748
2021-06-30 16:12:18.703248 | epoch 110 | time:  1.93s
2021-06-30 16:12:18.703408 -----------------------------------------------------------------------------------------
2021-06-30 16:12:20.960530 | epoch 112 | step 1780 |  ms/b 22.54 | train loss 0.927 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:23.236495 | epoch 113 | step 1800 |  ms/b 45.68 | train loss 3.423 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:25.574225 | epoch 114 | step 1820 |  ms/b 70.15 | train loss 0.641 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:27.855496 | epoch 115 | step 1840 |  ms/b 90.88 | train loss 0.726 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:30.165475 | epoch 117 | step 1860 |  ms/b 23.06 | train loss 1.555 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:32.450962 | epoch 118 | step 1880 |  ms/b 45.55 | train loss 6.453 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:34.764146 | epoch 119 | step 1900 |  ms/b 68.90 | train loss 84.592 | NA acc: 1.00 | not NA acc: 0.90  | tot acc: 0.95 
2021-06-30 16:12:37.020992 | epoch 120 | step 1920 |  ms/b 89.78 | train loss 33.098 | NA acc: 1.00 | not NA acc: 0.93  | tot acc: 0.96 
2021-06-30 16:12:37.021263 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:12:39.319698 ALL  : Theta 0.6469 | F1 0.5173 | AUC 0.4753
2021-06-30 16:12:39.327882 Ignore ma_f1 0.5173 | inhput_theta 0.6469 test_result P 0.5833 test_result R 0.4620 test_result F1 0.5156 | AUC 0.4753
2021-06-30 16:12:39.329719 | epoch 120 | time:  2.31s
2021-06-30 16:12:39.329765 -----------------------------------------------------------------------------------------
2021-06-30 16:12:45.035281 | epoch 122 | step 1940 |  ms/b 22.77 | train loss 149.245 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.97 
2021-06-30 16:12:47.320149 | epoch 123 | step 1960 |  ms/b 46.05 | train loss 154.605 | NA acc: 0.97 | not NA acc: 0.95  | tot acc: 0.96 
2021-06-30 16:12:49.608716 | epoch 124 | step 1980 |  ms/b 68.45 | train loss 182.175 | NA acc: 1.00 | not NA acc: 0.82  | tot acc: 0.91 
2021-06-30 16:12:51.896413 | epoch 125 | step 2000 |  ms/b 91.47 | train loss 134.226 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:12:54.185450 | epoch 127 | step 2020 |  ms/b 22.70 | train loss 130.176 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:56.466960 | epoch 128 | step 2040 |  ms/b 45.47 | train loss 153.526 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:12:58.753374 | epoch 129 | step 2060 |  ms/b 68.18 | train loss 149.033 | NA acc: 1.00 | not NA acc: 0.92  | tot acc: 0.96 
2021-06-30 16:13:01.088266 | epoch 130 | step 2080 |  ms/b 93.68 | train loss 86.112 | NA acc: 0.99 | not NA acc: 0.99  | tot acc: 0.99 
2021-06-30 16:13:01.088586 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:13:03.281448 ALL  : Theta 0.5482 | F1 0.4513 | AUC 0.4048
2021-06-30 16:13:03.289658 Ignore ma_f1 0.4513 | inhput_theta 0.5482 test_result P 0.5871 test_result R 0.3640 test_result F1 0.4494 | AUC 0.4048
2021-06-30 16:13:03.292708 | epoch 130 | time:  2.20s
2021-06-30 16:13:03.292754 -----------------------------------------------------------------------------------------
2021-06-30 16:13:05.581301 | epoch 132 | step 2100 |  ms/b 22.92 | train loss 53.858 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:13:07.885823 | epoch 133 | step 2120 |  ms/b 46.90 | train loss 152.714 | NA acc: 0.97 | not NA acc: 1.00  | tot acc: 0.99 
2021-06-30 16:13:10.291160 | epoch 134 | step 2140 |  ms/b 70.80 | train loss 98.493 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.98 
2021-06-30 16:13:12.601110 | epoch 135 | step 2160 |  ms/b 92.14 | train loss 79.710 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 
2021-06-30 16:13:18.564454 | epoch 137 | step 2180 |  ms/b 23.20 | train loss 115.452 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:13:20.858683 | epoch 138 | step 2200 |  ms/b 46.07 | train loss 88.053 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:13:23.149933 | epoch 139 | step 2220 |  ms/b 68.85 | train loss 83.672 | NA acc: 0.98 | not NA acc: 0.98  | tot acc: 0.98 
2021-06-30 16:13:25.433623 | epoch 140 | step 2240 |  ms/b 91.55 | train loss 54.835 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.97 
2021-06-30 16:13:25.433905 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:13:27.502823 ALL  : Theta 0.0001 | F1 0.5388 | AUC 0.5191
2021-06-30 16:13:27.511510 Ignore ma_f1 0.5388 | inhput_theta 0.0001 test_result P 0.6035 test_result R 0.4840 test_result F1 0.5372 | AUC 0.5191
2021-06-30 16:13:27.513898 | epoch 140 | time:  2.08s
2021-06-30 16:13:27.514031 -----------------------------------------------------------------------------------------
2021-06-30 16:13:30.006645 | epoch 142 | step 2260 |  ms/b 28.74 | train loss 78.501 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:13:32.336485 | epoch 143 | step 2280 |  ms/b 46.44 | train loss 94.368 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:13:34.647012 | epoch 144 | step 2300 |  ms/b 69.12 | train loss 419.068 | NA acc: 1.00 | not NA acc: 0.98  | tot acc: 0.99 
2021-06-30 16:13:36.961564 | epoch 145 | step 2320 |  ms/b 92.48 | train loss 285.042 | NA acc: 1.00 | not NA acc: 0.93  | tot acc: 0.96 
2021-06-30 16:13:39.260281 | epoch 147 | step 2340 |  ms/b 23.03 | train loss 127.416 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:13:41.580890 | epoch 148 | step 2360 |  ms/b 46.24 | train loss 149.514 | NA acc: 1.00 | not NA acc: 0.93  | tot acc: 0.96 
2021-06-30 16:13:43.892721 | epoch 149 | step 2380 |  ms/b 69.18 | train loss 145.366 | NA acc: 0.98 | not NA acc: 1.00  | tot acc: 0.99 
2021-06-30 16:13:46.256684 | epoch 150 | step 2400 |  ms/b 95.19 | train loss 154.763 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:13:46.256952 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:13:48.463732 ALL  : Theta 0.9797 | F1 0.5561 | AUC 0.4857
2021-06-30 16:13:48.471942 Ignore ma_f1 0.5561 | inhput_theta 0.9797 test_result P 0.6488 test_result R 0.4840 test_result F1 0.5544 | AUC 0.4857
2021-06-30 16:13:48.473816 | epoch 150 | time:  2.22s
2021-06-30 16:13:48.473859 -----------------------------------------------------------------------------------------
2021-06-30 16:13:54.343077 | epoch 152 | step 2420 |  ms/b 23.25 | train loss 370.875 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.97 
2021-06-30 16:13:56.682993 | epoch 153 | step 2440 |  ms/b 46.81 | train loss 172.619 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:13:59.042911 | epoch 154 | step 2460 |  ms/b 71.75 | train loss 283.410 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.97 
2021-06-30 16:14:01.409313 | epoch 155 | step 2480 |  ms/b 93.88 | train loss 173.409 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 
2021-06-30 16:14:03.752693 | epoch 157 | step 2500 |  ms/b 24.02 | train loss 324.678 | NA acc: 1.00 | not NA acc: 0.90  | tot acc: 0.95 
2021-06-30 16:14:06.050913 | epoch 158 | step 2520 |  ms/b 46.04 | train loss 290.218 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:14:08.368344 | epoch 159 | step 2540 |  ms/b 68.88 | train loss 1297.844 | NA acc: 1.00 | not NA acc: 0.85  | tot acc: 0.93 
2021-06-30 16:14:10.956549 | epoch 160 | step 2560 |  ms/b 106.60 | train loss 339.258 | NA acc: 1.00 | not NA acc: 0.93  | tot acc: 0.96 
2021-06-30 16:14:10.957075 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:14:13.187058 ALL  : Theta 0.1405 | F1 0.5346 | AUC 0.4793
2021-06-30 16:14:13.195203 Ignore ma_f1 0.5346 | inhput_theta 0.1405 test_result P 0.6801 test_result R 0.4380 test_result F1 0.5328 | AUC 0.4793
2021-06-30 16:14:13.196958 | epoch 160 | time:  2.24s
2021-06-30 16:14:13.197004 -----------------------------------------------------------------------------------------
2021-06-30 16:14:15.536974 | epoch 162 | step 2580 |  ms/b 23.02 | train loss 195.550 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:17.829857 | epoch 163 | step 2600 |  ms/b 45.78 | train loss 173.655 | NA acc: 1.00 | not NA acc: 0.93  | tot acc: 0.96 
2021-06-30 16:14:20.148782 | epoch 164 | step 2620 |  ms/b 70.06 | train loss 315.057 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.97 
2021-06-30 16:14:22.647469 | epoch 165 | step 2640 |  ms/b 98.01 | train loss 113.603 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:28.465634 | epoch 167 | step 2660 |  ms/b 23.29 | train loss 224.545 | NA acc: 1.00 | not NA acc: 0.80  | tot acc: 0.90 
2021-06-30 16:14:30.776084 | epoch 168 | step 2680 |  ms/b 46.44 | train loss 21.731 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:33.084453 | epoch 169 | step 2700 |  ms/b 69.30 | train loss 27.253 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:35.389238 | epoch 170 | step 2720 |  ms/b 92.32 | train loss 1.315 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:35.389545 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:14:37.482981 ALL  : Theta 0.0000 | F1 0.5896 | AUC 0.5713
2021-06-30 16:14:37.491088 Ignore ma_f1 0.5896 | inhput_theta 0.0000 test_result P 0.5680 test_result R 0.6100 test_result F1 0.5882 | AUC 0.5713
2021-06-30 16:14:37.492631 | epoch 170 | time:  2.10s
2021-06-30 16:14:37.492677 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:14:43.931099 | epoch 172 | step 2740 |  ms/b 23.46 | train loss 38.307 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:46.234344 | epoch 173 | step 2760 |  ms/b 45.86 | train loss 160.191 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:48.549263 | epoch 174 | step 2780 |  ms/b 69.92 | train loss 0.028 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:50.920431 | epoch 175 | step 2800 |  ms/b 95.63 | train loss 34.854 | NA acc: 1.00 | not NA acc: 0.99  | tot acc: 0.99 
2021-06-30 16:14:53.230152 | epoch 177 | step 2820 |  ms/b 22.97 | train loss 0.024 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:55.465438 | epoch 178 | step 2840 |  ms/b 44.68 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:14:57.791002 | epoch 179 | step 2860 |  ms/b 70.60 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:00.096668 | epoch 180 | step 2880 |  ms/b 92.48 | train loss 13.143 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:00.096962 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:15:02.185318 ALL  : Theta 0.0004 | F1 0.6056 | AUC 0.5768
2021-06-30 16:15:02.193344 Ignore ma_f1 0.6056 | inhput_theta 0.0004 test_result P 0.6024 test_result R 0.6060 test_result F1 0.6042 | AUC 0.5768
2021-06-30 16:15:02.195004 | epoch 180 | time:  2.10s
2021-06-30 16:15:02.195050 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:15:12.068155 | epoch 182 | step 2900 |  ms/b 28.48 | train loss 21.285 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:14.406188 | epoch 183 | step 2920 |  ms/b 46.22 | train loss 33.745 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:16.707336 | epoch 184 | step 2940 |  ms/b 69.05 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:19.005037 | epoch 185 | step 2960 |  ms/b 92.17 | train loss 34.559 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:21.367096 | epoch 187 | step 2980 |  ms/b 23.77 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:23.913073 | epoch 188 | step 3000 |  ms/b 47.59 | train loss 0.086 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:26.265125 | epoch 189 | step 3020 |  ms/b 70.37 | train loss 0.138 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:28.701421 | epoch 190 | step 3040 |  ms/b 98.25 | train loss 4.290 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:28.701863 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:15:30.864114 ALL  : Theta 0.0000 | F1 0.6259 | AUC 0.5890
2021-06-30 16:15:30.872246 Ignore ma_f1 0.6259 | inhput_theta 0.0000 test_result P 0.6270 test_result R 0.6220 test_result F1 0.6245 | AUC 0.5890
2021-06-30 16:15:30.873939 | epoch 190 | time:  2.17s
2021-06-30 16:15:30.874062 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:15:37.096882 | epoch 192 | step 3060 |  ms/b 23.66 | train loss 9.985 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:39.420360 | epoch 193 | step 3080 |  ms/b 45.99 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:41.698577 | epoch 194 | step 3100 |  ms/b 68.38 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:43.977767 | epoch 195 | step 3120 |  ms/b 91.11 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:49.749658 | epoch 197 | step 3140 |  ms/b 22.88 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:52.052869 | epoch 198 | step 3160 |  ms/b 45.67 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:54.333777 | epoch 199 | step 3180 |  ms/b 68.26 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:56.623958 | epoch 200 | step 3200 |  ms/b 91.71 | train loss 0.009 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:15:56.624224 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:15:58.719522 ALL  : Theta 0.9968 | F1 0.6142 | AUC 0.5760
2021-06-30 16:15:58.727546 Ignore ma_f1 0.6142 | inhput_theta 0.9968 test_result P 0.7010 test_result R 0.5440 test_result F1 0.6126 | AUC 0.5760
2021-06-30 16:15:58.729085 | epoch 200 | time:  2.10s
2021-06-30 16:15:58.729130 -----------------------------------------------------------------------------------------
2021-06-30 16:16:01.106461 | epoch 202 | step 3220 |  ms/b 23.62 | train loss 46.910 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:03.632110 | epoch 203 | step 3240 |  ms/b 46.88 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:06.001631 | epoch 204 | step 3260 |  ms/b 70.18 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:08.365608 | epoch 205 | step 3280 |  ms/b 94.66 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:10.658092 | epoch 207 | step 3300 |  ms/b 22.90 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:13.398539 | epoch 208 | step 3320 |  ms/b 51.55 | train loss 20.336 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:15.900128 | epoch 209 | step 3340 |  ms/b 77.56 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:18.234664 | epoch 210 | step 3360 |  ms/b 92.67 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:18.235085 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:16:20.322764 ALL  : Theta 0.0096 | F1 0.6205 | AUC 0.5941
2021-06-30 16:16:20.330761 Ignore ma_f1 0.6205 | inhput_theta 0.0096 test_result P 0.7013 test_result R 0.5540 test_result F1 0.6190 | AUC 0.5941
2021-06-30 16:16:20.332282 | epoch 210 | time:  2.10s
2021-06-30 16:16:20.332324 -----------------------------------------------------------------------------------------
2021-06-30 16:16:26.486191 | epoch 212 | step 3380 |  ms/b 22.73 | train loss 6.212 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:28.747946 | epoch 213 | step 3400 |  ms/b 45.18 | train loss 8.417 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:31.110889 | epoch 214 | step 3420 |  ms/b 71.87 | train loss 0.007 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:33.419411 | epoch 215 | step 3440 |  ms/b 92.35 | train loss 3.001 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:35.716185 | epoch 217 | step 3460 |  ms/b 23.20 | train loss 2.144 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:38.019840 | epoch 218 | step 3480 |  ms/b 45.94 | train loss 15.264 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 
2021-06-30 16:16:40.346101 | epoch 219 | step 3500 |  ms/b 69.44 | train loss 36.876 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:42.629117 | epoch 220 | step 3520 |  ms/b 91.38 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:42.629401 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:16:44.894730 ALL  : Theta 0.0000 | F1 0.6235 | AUC 0.6070
2021-06-30 16:16:44.902968 Ignore ma_f1 0.6235 | inhput_theta 0.0000 test_result P 0.6304 test_result R 0.6140 test_result F1 0.6221 | AUC 0.6070
2021-06-30 16:16:44.904596 | epoch 220 | time:  2.28s
2021-06-30 16:16:44.904645 -----------------------------------------------------------------------------------------
2021-06-30 16:16:47.230304 | epoch 222 | step 3540 |  ms/b 22.92 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:49.694679 | epoch 223 | step 3560 |  ms/b 54.33 | train loss 5.072 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:52.123441 | epoch 224 | step 3580 |  ms/b 70.91 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:16:54.480574 | epoch 225 | step 3600 |  ms/b 93.91 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:00.543273 | epoch 227 | step 3620 |  ms/b 23.55 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:02.908496 | epoch 228 | step 3640 |  ms/b 46.94 | train loss 1.487 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:05.349634 | epoch 229 | step 3660 |  ms/b 75.38 | train loss 2.196 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:07.849836 | epoch 230 | step 3680 |  ms/b 96.09 | train loss 5.591 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:07.850179 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:17:10.084001 ALL  : Theta 0.0000 | F1 0.6224 | AUC 0.6069
2021-06-30 16:17:10.092048 Ignore ma_f1 0.6224 | inhput_theta 0.0000 test_result P 0.6260 test_result R 0.6160 test_result F1 0.6210 | AUC 0.6069
2021-06-30 16:17:10.093649 | epoch 230 | time:  2.24s
2021-06-30 16:17:10.093709 -----------------------------------------------------------------------------------------
2021-06-30 16:17:12.386177 | epoch 232 | step 3700 |  ms/b 22.82 | train loss 6.515 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:14.685297 | epoch 233 | step 3720 |  ms/b 46.49 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:16.999844 | epoch 234 | step 3740 |  ms/b 69.83 | train loss 0.005 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:19.302437 | epoch 235 | step 3760 |  ms/b 91.89 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:21.579537 | epoch 237 | step 3780 |  ms/b 21.85 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:23.814653 | epoch 238 | step 3800 |  ms/b 44.61 | train loss 0.206 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:26.073974 | epoch 239 | step 3820 |  ms/b 68.54 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:28.350553 | epoch 240 | step 3840 |  ms/b 90.95 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:28.350985 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:17:30.329930 ALL  : Theta 0.0000 | F1 0.6216 | AUC 0.6089
2021-06-30 16:17:30.337978 Ignore ma_f1 0.6216 | inhput_theta 0.0000 test_result P 0.6265 test_result R 0.6140 test_result F1 0.6202 | AUC 0.6089
2021-06-30 16:17:30.339563 | epoch 240 | time:  1.99s
2021-06-30 16:17:30.339605 -----------------------------------------------------------------------------------------
2021-06-30 16:17:36.220043 | epoch 242 | step 3860 |  ms/b 22.91 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:38.577535 | epoch 243 | step 3880 |  ms/b 46.75 | train loss 10.460 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:40.908675 | epoch 244 | step 3900 |  ms/b 70.53 | train loss 0.035 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:43.283515 | epoch 245 | step 3920 |  ms/b 95.01 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:45.571593 | epoch 247 | step 3940 |  ms/b 23.47 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:47.850574 | epoch 248 | step 3960 |  ms/b 45.55 | train loss 2.689 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:50.142162 | epoch 249 | step 3980 |  ms/b 68.96 | train loss 1.022 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:52.473530 | epoch 250 | step 4000 |  ms/b 93.09 | train loss 0.012 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:52.473864 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:17:54.856217 ALL  : Theta 0.0000 | F1 0.6197 | AUC 0.6084
2021-06-30 16:17:54.864490 Ignore ma_f1 0.6197 | inhput_theta 0.0000 test_result P 0.6227 test_result R 0.6140 test_result F1 0.6183 | AUC 0.6084
2021-06-30 16:17:54.866365 | epoch 250 | time:  2.39s
2021-06-30 16:17:54.866523 -----------------------------------------------------------------------------------------
2021-06-30 16:17:57.399032 | epoch 252 | step 4020 |  ms/b 29.15 | train loss 0.142 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:17:59.765718 | epoch 253 | step 4040 |  ms/b 46.49 | train loss 0.116 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:02.142579 | epoch 254 | step 4060 |  ms/b 72.28 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:04.514213 | epoch 255 | step 4080 |  ms/b 94.62 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:10.912135 | epoch 257 | step 4100 |  ms/b 23.32 | train loss 1.147 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:13.340149 | epoch 258 | step 4120 |  ms/b 50.53 | train loss 3.907 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:15.637139 | epoch 259 | step 4140 |  ms/b 68.91 | train loss 12.150 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:17.915720 | epoch 260 | step 4160 |  ms/b 90.91 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:17.915993 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:18:20.166081 ALL  : Theta 0.0000 | F1 0.6234 | AUC 0.6035
2021-06-30 16:18:20.174403 Ignore ma_f1 0.6234 | inhput_theta 0.0000 test_result P 0.6124 test_result R 0.6320 test_result F1 0.6220 | AUC 0.6035
2021-06-30 16:18:20.176186 | epoch 260 | time:  2.26s
2021-06-30 16:18:20.176327 -----------------------------------------------------------------------------------------
2021-06-30 16:18:22.486833 | epoch 262 | step 4180 |  ms/b 23.15 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:24.821974 | epoch 263 | step 4200 |  ms/b 46.15 | train loss 16.039 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:27.132757 | epoch 264 | step 4220 |  ms/b 69.47 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:29.442444 | epoch 265 | step 4240 |  ms/b 92.32 | train loss 5.879 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:31.748994 | epoch 267 | step 4260 |  ms/b 23.50 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:34.130156 | epoch 268 | step 4280 |  ms/b 48.77 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:36.526085 | epoch 269 | step 4300 |  ms/b 73.13 | train loss 28.621 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:38.902172 | epoch 270 | step 4320 |  ms/b 94.85 | train loss 12.822 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:38.902862 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:18:41.100120 ALL  : Theta 0.0009 | F1 0.6417 | AUC 0.6033
2021-06-30 16:18:41.108162 Ignore ma_f1 0.6417 | inhput_theta 0.0009 test_result P 0.7143 test_result R 0.5800 test_result F1 0.6402 | AUC 0.6033
2021-06-30 16:18:41.109812 | epoch 270 | time:  2.21s
2021-06-30 16:18:41.109853 -----------------------------------------------------------------------------------------
/home/ubuntu/anaconda3/envs/GAIN/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2021-06-30 16:18:51.470787 | epoch 272 | step 4340 |  ms/b 23.38 | train loss 0.785 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:53.784982 | epoch 273 | step 4360 |  ms/b 45.81 | train loss 0.050 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:56.055913 | epoch 274 | step 4380 |  ms/b 67.99 | train loss 6.052 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:18:58.251919 | epoch 275 | step 4400 |  ms/b 87.80 | train loss 8.518 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:00.493201 | epoch 277 | step 4420 |  ms/b 22.02 | train loss 33.602 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:02.950996 | epoch 278 | step 4440 |  ms/b 50.33 | train loss 5.051 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:05.314831 | epoch 279 | step 4460 |  ms/b 69.70 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:07.778086 | epoch 280 | step 4480 |  ms/b 99.13 | train loss 18.822 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:07.778422 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:19:10.002805 ALL  : Theta 0.0291 | F1 0.6358 | AUC 0.5562
2021-06-30 16:19:10.010932 Ignore ma_f1 0.6358 | inhput_theta 0.0291 test_result P 0.6704 test_result R 0.6020 test_result F1 0.6344 | AUC 0.5562
2021-06-30 16:19:10.012492 | epoch 280 | time:  2.23s
2021-06-30 16:19:10.012536 -----------------------------------------------------------------------------------------
2021-06-30 16:19:12.488425 | epoch 282 | step 4500 |  ms/b 29.66 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:15.199688 | epoch 283 | step 4520 |  ms/b 47.99 | train loss 40.491 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:17.637619 | epoch 284 | step 4540 |  ms/b 70.67 | train loss 7.619 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:19.916764 | epoch 285 | step 4560 |  ms/b 90.99 | train loss 22.864 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:25.802411 | epoch 287 | step 4580 |  ms/b 23.18 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:28.086985 | epoch 288 | step 4600 |  ms/b 46.20 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:30.402093 | epoch 289 | step 4620 |  ms/b 68.96 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:32.739730 | epoch 290 | step 4640 |  ms/b 93.66 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:32.740027 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:19:34.812763 ALL  : Theta 0.0426 | F1 0.6410 | AUC 0.5659
2021-06-30 16:19:34.820754 Ignore ma_f1 0.6410 | inhput_theta 0.0426 test_result P 0.6874 test_result R 0.5980 test_result F1 0.6396 | AUC 0.5659
2021-06-30 16:19:34.822351 | epoch 290 | time:  2.08s
2021-06-30 16:19:34.822393 -----------------------------------------------------------------------------------------
2021-06-30 16:19:37.096217 | epoch 292 | step 4660 |  ms/b 22.77 | train loss 0.032 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:39.399481 | epoch 293 | step 4680 |  ms/b 46.31 | train loss 0.054 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:41.705436 | epoch 294 | step 4700 |  ms/b 69.21 | train loss 0.043 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:44.123497 | epoch 295 | step 4720 |  ms/b 98.02 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:46.442563 | epoch 297 | step 4740 |  ms/b 22.91 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:48.705846 | epoch 298 | step 4760 |  ms/b 45.47 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:50.989127 | epoch 299 | step 4780 |  ms/b 68.47 | train loss 0.000 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:53.307686 | epoch 300 | step 4800 |  ms/b 92.60 | train loss 10.208 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 
2021-06-30 16:19:53.307995 -----------------------------------------------------------------------------------------
step: 0/32
step: 1/32
step: 2/32
step: 3/32
step: 4/32
step: 5/32
step: 6/32
step: 7/32
step: 8/32
step: 9/32
step: 10/32
step: 11/32
step: 12/32
step: 13/32
step: 14/32
step: 15/32
step: 16/32
step: 17/32
step: 18/32
step: 19/32
step: 20/32
step: 21/32
step: 22/32
step: 23/32
step: 24/32
step: 25/32
step: 26/32
step: 27/32
step: 28/32
step: 29/32
step: 30/32
step: 31/32
2021-06-30 16:19:55.531666 ALL  : Theta 0.0000 | F1 0.6259 | AUC 0.5556
2021-06-30 16:19:55.539902 Ignore ma_f1 0.6259 | inhput_theta 0.0000 test_result P 0.6487 test_result R 0.6020 test_result F1 0.6245 | AUC 0.5556
2021-06-30 16:19:55.541848 | epoch 300 | time:  2.23s
2021-06-30 16:19:55.541902 -----------------------------------------------------------------------------------------
Finish training
Best epoch = 270 | Best Ign F1 = 0.641676
Storing best result...
Finish storing
